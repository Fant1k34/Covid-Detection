{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:53:55.982305Z",
     "iopub.status.busy": "2021-11-20T10:53:55.98168Z",
     "iopub.status.idle": "2021-11-20T10:54:00.005903Z",
     "shell.execute_reply": "2021-11-20T10:54:00.004647Z",
     "shell.execute_reply.started": "2021-11-20T10:53:55.982161Z"
    },
    "id": "pleasant-despite"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:55:39.09681Z",
     "iopub.status.busy": "2021-11-20T10:55:39.096479Z",
     "iopub.status.idle": "2021-11-20T10:55:39.102727Z",
     "shell.execute_reply": "2021-11-20T10:55:39.102059Z",
     "shell.execute_reply.started": "2021-11-20T10:55:39.096775Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:55:40.457263Z",
     "iopub.status.busy": "2021-11-20T10:55:40.456539Z",
     "iopub.status.idle": "2021-11-20T10:55:40.466141Z",
     "shell.execute_reply": "2021-11-20T10:55:40.464998Z",
     "shell.execute_reply.started": "2021-11-20T10:55:40.457214Z"
    },
    "id": "fPzy_fsGGLra",
    "outputId": "ca7886fb-0ebf-42be-fa32-5ba23f5bbaf2"
   },
   "outputs": [],
   "source": [
    "for put, papki, files in os.walk(\"../input/tgcovid/data/data/labels\"):\n",
    "    print(put, papki, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0WGmVHdGLyt",
    "outputId": "71df4f61-58cc-4673-f1c9-f48af0f7e9c9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:55:42.096229Z",
     "iopub.status.busy": "2021-11-20T10:55:42.095452Z",
     "iopub.status.idle": "2021-11-20T10:55:42.100656Z",
     "shell.execute_reply": "2021-11-20T10:55:42.100079Z",
     "shell.execute_reply.started": "2021-11-20T10:55:42.09618Z"
    },
    "id": "4h6e91ZqVqQq"
   },
   "outputs": [],
   "source": [
    "core_path = \"../input/tgcovid/\"\n",
    "path = core_path + \"data/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:55:42.437987Z",
     "iopub.status.busy": "2021-11-20T10:55:42.437578Z",
     "iopub.status.idle": "2021-11-20T10:55:42.449846Z",
     "shell.execute_reply": "2021-11-20T10:55:42.449121Z",
     "shell.execute_reply.started": "2021-11-20T10:55:42.437957Z"
    },
    "id": "excited-genome",
    "outputId": "13673278-cde9-4ce8-cce4-137f60702239"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(path + \"images\") if isfile(join(path + \"images\", f))]\n",
    "onlyfiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:55:43.653267Z",
     "iopub.status.busy": "2021-11-20T10:55:43.652965Z",
     "iopub.status.idle": "2021-11-20T10:55:59.568965Z",
     "shell.execute_reply": "2021-11-20T10:55:59.56811Z",
     "shell.execute_reply.started": "2021-11-20T10:55:43.653229Z"
    },
    "id": "extended-dragon",
    "outputId": "bf442a1c-c71a-49e9-9b84-acec6df6b36c"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load training data into images and labels lists\n",
    "\n",
    "images list consists of CT scans -  numpy arrays of shape (512, 512, n_slices)\n",
    "labels list consists of ground truth masks -  numpy arrays of shape (512, 512, n_slices), where:\n",
    "    0 - background class\n",
    "    1 - regions of consolidation class\n",
    "\"\"\"\n",
    "\n",
    "# path = './data/data' # Replace this line with path to data directory\n",
    "path_images = os.path.join(path, 'images')\n",
    "path_labels = os.path.join(path, 'labels')\n",
    "with open(core_path + 'training_data.json', 'r') as f:\n",
    "    dict_training = json.load(f)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for entry in tqdm(dict_training):\n",
    "    # print(os.path.join(path_images, entry['image']))\n",
    "    image = nib.load(os.path.join(path_images, entry['image'][:-3]))\n",
    "    label = nib.load(os.path.join(path_labels, entry['label'][:-3]))\n",
    "    images.append(image.get_fdata())\n",
    "    labels.append(label.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "genetic-roulette"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:55:59.571006Z",
     "iopub.status.busy": "2021-11-20T10:55:59.570751Z",
     "iopub.status.idle": "2021-11-20T10:56:00.378707Z",
     "shell.execute_reply": "2021-11-20T10:56:00.378003Z",
     "shell.execute_reply.started": "2021-11-20T10:55:59.570974Z"
    },
    "id": "transparent-apache",
    "outputId": "96c6b8ca-0dc2-4b8f-d4f2-c979d464077c"
   },
   "outputs": [],
   "source": [
    "#Visualize some of the slices\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def blend(image, mask): # Функция возвращает картинку с наложенной на неё маской - label, которые являются ковидной штукой\n",
    "    image = image.astype(np.float32)\n",
    "    min_in = image.min()\n",
    "    max_in = image.max()\n",
    "    image = (image - min_in) / (max_in - min_in + 1e-8) * 255\n",
    "    image = np.dstack((image, image, image)).astype(np.uint8)\n",
    "    zeros = np.zeros_like(mask)\n",
    "    mask = np.dstack((zeros, zeros, mask * 255)).astype(np.uint8)\n",
    "    return Image.blend(\n",
    "        Image.fromarray(image),\n",
    "        Image.fromarray(mask),\n",
    "        alpha=.3\n",
    "    )\n",
    "\n",
    "patient_num = 7\n",
    "slices_num = (10, 20, 30)\n",
    "slices = []\n",
    "for idx in slices_num:\n",
    "    slices.append(blend(\n",
    "        images[patient_num][..., idx],\n",
    "        labels[patient_num][..., idx]\n",
    "    ))\n",
    "\n",
    "figure = plt.figure(figsize=(18, 18))\n",
    "for i, image in enumerate(slices):\n",
    "    ax = figure.add_subplot(1, len(slices), i + 1)\n",
    "    ax.imshow(slices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "regulated-memphis"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:00.381052Z",
     "iopub.status.busy": "2021-11-20T10:56:00.379951Z",
     "iopub.status.idle": "2021-11-20T10:56:00.387578Z",
     "shell.execute_reply": "2021-11-20T10:56:00.386517Z",
     "shell.execute_reply.started": "2021-11-20T10:56:00.380991Z"
    },
    "id": "annual-cherry",
    "outputId": "06a036ad-0392-4a4f-9bb6-b6f90460a8f9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write your code here\n",
    "\n",
    "You need to:\n",
    " 0. (Optional) Split your data into training and validation sets.\n",
    " 1. Create batch generator\n",
    " 2. Define and train your model using deep learning framework, e.g. PyTorch or Keras\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:00.389896Z",
     "iopub.status.busy": "2021-11-20T10:56:00.389651Z",
     "iopub.status.idle": "2021-11-20T10:56:00.400662Z",
     "shell.execute_reply": "2021-11-20T10:56:00.399637Z",
     "shell.execute_reply.started": "2021-11-20T10:56:00.389867Z"
    },
    "id": "statistical-middle"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, \n",
    "                                                    train_size=0.8, \n",
    "                                                    random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:00.402535Z",
     "iopub.status.busy": "2021-11-20T10:56:00.402214Z",
     "iopub.status.idle": "2021-11-20T10:56:00.414113Z",
     "shell.execute_reply": "2021-11-20T10:56:00.41313Z",
     "shell.execute_reply.started": "2021-11-20T10:56:00.402494Z"
    },
    "id": "nRyql7DDXwsz"
   },
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    # Гауссовый шум\n",
    "    A.GaussNoise(always_apply=False, p=0.5, var_limit=(105.69999694824219, 496.6399841308594)),\n",
    "    # Отражение\n",
    "    # A.Flip(always_apply=False, p=0.5),\n",
    "    # Рандомное сжатие\n",
    "    A.GridDistortion(always_apply=False, p=0.5, num_steps=3, distort_limit=(-0.30000001192092896, 0.30000001192092896), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "    # Отражение\n",
    "    # A.HorizontalFlip(always_apply=False, p=0.5),\n",
    "    # Блюр в движении (резкий поворот камеры)\n",
    "    A.MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 9)),\n",
    "    # Шум\n",
    "    # A.MultiplicativeNoise(always_apply=False, p=0.5, multiplier=(0.8899999856948853, 1.1699999570846558), per_channel=True, elementwise=True),\n",
    "    # Искажение\n",
    "    # A.OpticalDistortion(always_apply=False, p=0.5, distort_limit=(-0.5, 0.5), shift_limit=(-0.05000000074505806, 0.05000000074505806), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "    # Шум\n",
    "    A.RandomGamma(always_apply=False, p=0.5, gamma_limit=(80, 120), eps=1e-07),\n",
    "    # Случайный поворот\n",
    "    # A.VerticalFlip(always_apply=False, p=0.5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:00.41709Z",
     "iopub.status.busy": "2021-11-20T10:56:00.416647Z",
     "iopub.status.idle": "2021-11-20T10:56:00.433205Z",
     "shell.execute_reply": "2021-11-20T10:56:00.431993Z",
     "shell.execute_reply.started": "2021-11-20T10:56:00.417026Z"
    },
    "id": "dried-ireland"
   },
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, X_train, X_val, Y_train, Y_val, transforms):\n",
    "        self.X_train = []\n",
    "        self.X_val = []\n",
    "        self.Y_train = []\n",
    "        self.Y_val = []\n",
    "        self.transforms = transforms\n",
    "\n",
    "        print(torch.Tensor(X_train[0]).transpose(1, 2).transpose(0, 1)[0].shape)\n",
    "        for ct in X_train:\n",
    "            ct = torch.Tensor(ct)\n",
    "            # .contiguous().view(ct.shape[2], ct.shape[1], ct.shape[0]).transpose(0, 1).transpose(1, 2)\n",
    "            for sloy in ct.transpose(1, 2).transpose(0, 1):\n",
    "                self.X_train.append(sloy)\n",
    "        \n",
    "        for ct in X_val:\n",
    "            ct = torch.Tensor(ct)\n",
    "            for sloy in ct.transpose(1, 2).transpose(0, 1):\n",
    "                self.X_val.append(sloy)\n",
    "\n",
    "        for ct in Y_train:\n",
    "            ct = torch.Tensor(ct)\n",
    "            for sloy in ct.transpose(1, 2).transpose(0, 1):\n",
    "                self.Y_train.append(sloy)\n",
    "        \n",
    "        for ct in Y_val:\n",
    "            ct = torch.Tensor(ct)\n",
    "            for sloy in ct.transpose(1, 2).transpose(0, 1):\n",
    "                self.Y_val.append(sloy)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sl = self.transforms(image=self.X_train[idx].numpy(), label=self.Y_train[idx].numpy())\n",
    "        return torch.Tensor([sl[\"image\"]]), torch.Tensor([sl[\"label\"]]) # Важно, нельзя передать просто картинку (512, 512), так как используется свёртка по многим измерениям. Необходимо передать в формате\n",
    "                                            # [палитра, ширина, высота, номер картинки]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:00.435465Z",
     "iopub.status.busy": "2021-11-20T10:56:00.434852Z",
     "iopub.status.idle": "2021-11-20T10:56:03.483958Z",
     "shell.execute_reply": "2021-11-20T10:56:03.48308Z",
     "shell.execute_reply.started": "2021-11-20T10:56:00.435413Z"
    },
    "id": "complimentary-midwest",
    "outputId": "54b84c10-0e61-42cf-8561-39ad47f19d90"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataset = CovidDataset(X_train, X_val, y_train, y_val, transforms)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:03.485583Z",
     "iopub.status.busy": "2021-11-20T10:56:03.485348Z",
     "iopub.status.idle": "2021-11-20T10:56:03.513592Z",
     "shell.execute_reply": "2021-11-20T10:56:03.512468Z",
     "shell.execute_reply.started": "2021-11-20T10:56:03.485552Z"
    },
    "id": "linear-approval",
    "outputId": "c03bd93f-4562-49d7-e3ae-2f9af31930b2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def block_down(self, in_features, out_features):\n",
    "        return nn.Sequential(*[nn.Conv2d(in_features, out_features, (3, 3), padding=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.BatchNorm2d(out_features)])\n",
    "    \n",
    "    def block_up(self, in_features, out_features):\n",
    "        return nn.Sequential(*[nn.Conv2d(in_features, out_features, (3, 3), padding=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.BatchNorm2d(out_features)])\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        self.block_up11 = self.block_down(1, 32)\n",
    "        self.block_up12 = self.block_down(32, 32)\n",
    "        self.max_pooling11 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.block_up21 = self.block_down(32, 64)\n",
    "        self.block_up22 = self.block_down(64, 64)\n",
    "        self.max_pooling22 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.block_up31 = self.block_down(64, 128)\n",
    "        self.block_up32 = self.block_down(128, 128)\n",
    "        self.max_pooling33 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.block_up41 = self.block_down(128, 256)\n",
    "        self.block_up42 = self.block_down(256, 256)\n",
    "        self.max_pooling44 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.block_up51 = self.block_down(256, 512)\n",
    "        self.block_up52 = self.block_down(512, 512)\n",
    "        \n",
    "        self.block_up61 = nn.Upsample(scale_factor=2)\n",
    "        self.block_up62 = self.block_up(512, 256)\n",
    "        self.block_up63 = self.block_up(256, 256)\n",
    "        self.block_up64 = self.block_up(256, 256)\n",
    "        \n",
    "        self.block_up71 = nn.Upsample(scale_factor=2)\n",
    "        self.block_up72 = self.block_up(256, 128)\n",
    "        self.block_up73 = self.block_up(128, 128)\n",
    "        self.block_up74 = self.block_up(128, 128)\n",
    "        \n",
    "        self.block_up81 = nn.Upsample(scale_factor=2)\n",
    "        self.block_up82 = self.block_up(128, 64)\n",
    "        self.block_up83 = self.block_up(64, 64)\n",
    "        self.block_up84 = self.block_up(64, 64)\n",
    "        \n",
    "        self.block_up91 = nn.Upsample(scale_factor=2)\n",
    "        self.block_up92 = self.block_up(64, 32)\n",
    "        self.block_up93 = self.block_up(32, 32)\n",
    "        self.block_up94 = self.block_up(32, 32)\n",
    "        \n",
    "        self.block_up100 = self.block_up(32, 1) \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.block_up11(x)\n",
    "        out = self.block_up12(out)\n",
    "        \n",
    "        save1 = out.clone()\n",
    "        \n",
    "        out = self.max_pooling11(out)\n",
    "        \n",
    "        out = self.block_up21(out)\n",
    "        out = self.block_up22(out)\n",
    "        \n",
    "        save2 = out.clone()\n",
    "        \n",
    "        out = self.max_pooling22(out)\n",
    "        \n",
    "        out = self.block_up31(out)\n",
    "        out = self.block_up32(out)\n",
    "        \n",
    "        save3 = out.clone()\n",
    "        \n",
    "        out = self.max_pooling33(out)\n",
    "        \n",
    "        out = self.block_up41(out)\n",
    "        out = self.block_up42(out)\n",
    "        \n",
    "        save4 = out.clone()\n",
    "        \n",
    "        out = self.max_pooling44(out)\n",
    "        \n",
    "        out = self.block_up51(out)\n",
    "        out = self.block_up52(out)\n",
    "        \n",
    "        \n",
    "        out = self.block_up61(out)\n",
    "        out = self.block_up62(out)\n",
    "        out = self.block_up63(out + save4)\n",
    "        out = self.block_up64(out)\n",
    "\n",
    "        out = self.block_up71(out)\n",
    "        out = self.block_up72(out)\n",
    "        out = self.block_up73(out + save3)\n",
    "        out = self.block_up74(out)\n",
    "\n",
    "        out = self.block_up81(out)\n",
    "        out = self.block_up82(out)\n",
    "        out = self.block_up83(out + save2)\n",
    "        out = self.block_up84(out)\n",
    "\n",
    "        out = self.block_up91(out)\n",
    "        out = self.block_up92(out)\n",
    "        out = self.block_up93(out + save1)\n",
    "        out = self.block_up94(out)\n",
    "\n",
    "        out = self.block_up100(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snxDIdI4tGSg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOR5rO8rtGVB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:03.515407Z",
     "iopub.status.busy": "2021-11-20T10:56:03.515167Z",
     "iopub.status.idle": "2021-11-20T10:56:03.53146Z",
     "shell.execute_reply": "2021-11-20T10:56:03.530381Z",
     "shell.execute_reply.started": "2021-11-20T10:56:03.515379Z"
    },
    "id": "GOguN693tGXO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"none\"):\n",
    "    \"\"\"\n",
    "    Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py .\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs: A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default = 0.25\n",
    "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
    "               balance easy vs hard examples.\n",
    "        reduction: 'none' | 'mean' | 'sum'\n",
    "                 'none': No reduction will be applied to the output.\n",
    "                 'mean': The output will be averaged.\n",
    "                 'sum': The output will be summed.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    p = torch.sigmoid(inputs)\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(\n",
    "        inputs, targets, reduction=\"none\"\n",
    "    )\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    if reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2_e4NfqtGZj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRFuRUR2tGcK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:03.534263Z",
     "iopub.status.busy": "2021-11-20T10:56:03.533726Z",
     "iopub.status.idle": "2021-11-20T10:56:03.652985Z",
     "shell.execute_reply": "2021-11-20T10:56:03.652053Z",
     "shell.execute_reply.started": "2021-11-20T10:56:03.534194Z"
    },
    "id": "ADDRhSNMcf47"
   },
   "outputs": [],
   "source": [
    "num_epoch = 25\n",
    "lr = 0.01\n",
    "\n",
    "model = Unet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = sigmoid_focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBqTECELcf7N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:08.71322Z",
     "iopub.status.busy": "2021-11-20T10:56:08.712324Z",
     "iopub.status.idle": "2021-11-20T10:56:08.719771Z",
     "shell.execute_reply": "2021-11-20T10:56:08.718779Z",
     "shell.execute_reply.started": "2021-11-20T10:56:08.713171Z"
    },
    "id": "RVOxRVzjcf_j"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T10:56:31.338153Z",
     "iopub.status.busy": "2021-11-20T10:56:31.337805Z"
    },
    "id": "B8hszaOgcgBi",
    "outputId": "d825adf7-676c-40e4-bda7-44f664635095"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    for X, Y in loader:\n",
    "        # X = X.to(device)\n",
    "        # Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        \n",
    "        print(X.shape)\n",
    "        print(Y.shape)\n",
    "\n",
    "        loss = criterion(output, Y, 0.25, 15, \"mean\")\n",
    "        loss.backward()\n",
    "\n",
    "        del X\n",
    "        del Y\n",
    "        torch.cuda.empty_cache()\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1ZYvXz5cgDm"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"ct_detector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO4WFgHmcgGa"
   },
   "outputs": [],
   "source": [
    "def blend2(image, mask): # Функция возвращает картинку с наложенной на неё маской - label, которые являются ковидной штукой\n",
    "    # image = image.astype(np.float32)\n",
    "    min_in = image.min()\n",
    "    max_in = image.max()\n",
    "    image = (image - min_in) / (max_in - min_in + 1e-8) * 255\n",
    "    image = np.dstack((image, image, image)).astype(np.uint8)\n",
    "    zeros = np.zeros_like(mask)\n",
    "    mask = np.dstack((zeros, zeros, mask * 255)).astype(np.uint8)\n",
    "    return Image.blend(\n",
    "        Image.fromarray(image),\n",
    "        Image.fromarray(mask),\n",
    "        alpha=.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_tepmTmcgIQ",
    "outputId": "7e24ef7c-10c2-4013-f37f-22d0bca85875"
   },
   "outputs": [],
   "source": [
    "for patient in range(len(X_val)):\n",
    "    for sloy in range(len(X_val[patient])):\n",
    "        blend2(X_val[patient][..., sloy], y_val[patient][..., sloy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wZ9kxshOSZR",
    "outputId": "924532ec-943c-4b59-9c0f-5c004d3453e1"
   },
   "outputs": [],
   "source": [
    "blend2(X_val[2][..., 25], y_val[2][..., 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y6QtEWdOYnp",
    "outputId": "a27f91b5-8f58-46dc-e0e0-e71085ac8c86"
   },
   "outputs": [],
   "source": [
    "output = model(torch.Tensor([[X_val[2][..., 25]], [X_val[2][..., 26]], [X_val[2][..., 27]], [X_val[2][..., 28]]]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc4vGaAQOY43",
    "outputId": "e107a83e-f5ea-4c1a-8801-a2f2033e0969"
   },
   "outputs": [],
   "source": [
    "i = 0 # X_val[i][..., 25 + i]\n",
    "blend2(torch.ones_like(torch.Tensor(X_val[i][..., 25 + i])), output[i][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "official-boundary",
    "outputId": "1ae4ab7d-38c9-4a84-bfe3-9cc3358e91d4"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrong-serial"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load testing data into images and labels lists\n",
    "\n",
    "images list consists of CT scans -  numpy arrays of shape (512, 512, n_slices)\n",
    "\"\"\"\n",
    "with open('testing_data.json', 'r') as f:\n",
    "    dict_testing = json.load(f)\n",
    "\n",
    "images_testig = []\n",
    "for entry in tqdm(dict_testing):\n",
    "    image = nib.load(os.path.join(path_images, entry['image']))\n",
    "    images.append(image.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optimum-attitude"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write your code here\n",
    "\n",
    "You need to:\n",
    " 1. Predict labels for CT scans from images list\n",
    " 2. Store them in the labels_predicted list in form of numpy arrays of shape (512, 512, n_slices), where:\n",
    "    0 - background class\n",
    "    1 - regions of consolidation class\n",
    "\"\"\"\n",
    "labels_predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "younger-doubt"
   },
   "outputs": [],
   "source": [
    "# Visualize some of the predictions\n",
    "\n",
    "patient_num = 5\n",
    "slices_num = (10, 20, 30)\n",
    "slices = []\n",
    "for idx in slices_num:\n",
    "    slices.append(blend(\n",
    "        images[patient_num][..., idx],\n",
    "        labels_predicted[patient_num][..., idx]\n",
    "    ))\n",
    "\n",
    "figure = plt.figure(figsize=(18, 18))\n",
    "for i, image in enumerate(slices):\n",
    "    ax = figure.add_subplot(1, len(slices), i + 1)\n",
    "    ax.imshow(slices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veterinary-canvas"
   },
   "outputs": [],
   "source": [
    "# Execute this cell for submission file generation \n",
    "import csv\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1):\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return [str(item) for item in run_lengths]\n",
    "\n",
    "with open(\"submission.csv\", \"wt\") as sb:\n",
    "    submission_writer = csv.writer(sb, delimiter=',')\n",
    "    submission_writer.writerow([\"Id\", \"Predicted\"])\n",
    "    for idx, patient in tqdm(enumerate(labels_predicted)):\n",
    "        submission_writer.writerow([\n",
    "                f\"{idx}\",\n",
    "                \" \".join(rle_encoding(patient))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhmLoFX3yOxR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
